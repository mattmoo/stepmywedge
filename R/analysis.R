#' Construct a statistic distribution generated by permuting sites to different
#' clusters.
#'
#' Statistic is Wilcoxon-Mann-Whitney at the moment.
#'
#' @param max.r How many permutations?
#' @param outcome.col.name Name of the column containing the outcome
#' @param intervention.col.name NAme of the column containing the intervention
#'   (i.e. has levels "control" and "intervention")
#' @param stat.per.site If TRUE, the statistic will be calculated separately for
#'   each site on each permutation, if not site will be ignored. MAy not be a
#'   good idea to use TRUE
#' @param statistic Can be WMWU, ANOVA, mean_diff, chisq, or risk_ratio.
#' @param ... Passed on to the test
#' @return A data.table with the statistic value at each permutation (with zero
#'   as the unpermuted comparison). May be divided by site if requested.
#' @export
generate.stat.dt = function(max.r,
                            outcome.col.name,
                            intervention.col.name,
                            data.dt,
                            cluster.dt,
                            study.dt,
                            site.dt,
                            perm.dt = NULL,
                            stat.dt.level = c('study', 'cluster', 'site')[1],
                            equal.weight.site = F,
                            equal.weight.cluster = F,
                            statistic = 'WMWU',
                            other.predictors = NULL,
                            # sort.input = T,
                            progress.bar = T,
                            ...) {

  #It will probably streamline the calculations if I precalculate the intervention
  #and control groups for each site for each cluster (i.e. sequence).
  #This could fail for very large data sets.

  hypothetical.data.dt = data.table::data.table(expand.grid(randomisation.group = study.dt[, unique(randomisation.group)], cluster = study.dt[, levels(cluster)]))
  hypothetical.data.dt = merge(
    x = hypothetical.data.dt,
    y = unique(site.dt[, .(randomisation.group, site)]),
    by = 'randomisation.group',
    allow.cartesian = TRUE
  )


  # if (sort.input == T) {
  setorderv(data.dt, cols = c(outcome.col.name, intervention.col.name))
  # }

  #Make a wee progress bar.
  message(paste0("Calculating ", nrow(hypothetical.data.dt), " hypothetical site data tables..."))
  if (progress.bar == T) {
    pb = txtProgressBar(style = 3, char = '|')
  }

  for (row.ind in 1:nrow(hypothetical.data.dt)) {
    #Make a table of what the groups would look like if that site was in that cluster.
    site.cluster.dt = data.dt[site == hypothetical.data.dt[row.ind, site],c("time","site",outcome.col.name), with=F]
    data.table::set(x = site.cluster.dt,
                    j = "cluster",
                    value = hypothetical.data.dt[row.ind, cluster])
    #Chuck on the time markers.
    site.cluster.dt = data.table:::merge.data.table(site.cluster.dt, cluster.dt, by = "cluster")
    #Calculate which group the subject is in.
    data.table::set(x = site.cluster.dt,
                    j = intervention.col.name,
                    value = "control")
    data.table::set(x = site.cluster.dt,
                    i = which(site.cluster.dt[,time>=transition.start.time]),
                    j = intervention.col.name,
                    value = "transition")
    data.table::set(x = site.cluster.dt,
                    i = which(site.cluster.dt[,time>=intervention.start.time]),
                    j = intervention.col.name,
                    value = "intervention")
    data.table::set(x = site.cluster.dt,
                    j = intervention.col.name,
                    value = factor(site.cluster.dt[,get(intervention.col.name)],
                                   levels = c("control",
                                              "transition",
                                              "intervention")))

    #Add that table to the hypothetical data.
    data.table::set(x = hypothetical.data.dt,
                    i = row.ind,
                    j = "data.dt",
                    value = list(list(site.cluster.dt)))

    #Update progress
    if (progress.bar == T) {
      setTxtProgressBar(pb, row.ind/nrow(hypothetical.data.dt))
    }
  }


  if (progress.bar == T) {
    close(pb)
  }

  #Now let's figure out how to permute things.
  if (is.null(perm.dt)) {
    perm.dt = generate.perm.dt(study.dt, max.r = max.r)
    print(perm.dt)
  } else if (perm.dt[, uniqueN(permutation)] != max.r) {
    message(paste0("Number of permutations in perm.dt: ", (perm.dt[, uniqueN(permutation)])))
    message(paste0("Number of requested permutations: ", max.r))
    if (perm.dt[, uniqueN(permutation)] > max.r) {
      message(paste0("First ", max.r, " permutations will be used."))
    } else {
      message(paste0("max.r changed to "), (perm.dt[, uniqueN(permutation)]))
      max.r = perm.dt[, uniqueN(permutation)]
    }
  }


  #Set up a table for stats from all permutations, differs in dimension
  #depending on whether you want one stat per site or not.
  if (!stat.per.site) {
    stat.dt = data.table::data.table(perm.num = 0:max.r,
                                     stat = NA_real_)
  } else {
    stat.dt = data.table::data.table(perm.num = rep(0:max.r,
                                                    times = 1,
                                                    each = nrow(study.dt)),
                                     site = rep(study.dt$site, times = max.r+1),
                                     stat = NA_real_)
  }

  #Flag original data in permutations
  data.table::set(x = stat.dt,
                  j = 'permuted',
                  value = factor(stat.dt$perm.num != 0))

  #Make a wee progress bar.
  message(paste0("Calculating ", max.r, " permutations..."))

  if (progress.bar == T) {
    pb = txtProgressBar(style = 3, char = '|')
  }
  next.progress = 0
  t = Sys.time()

  #Formula for the stats
  # form = as.formula(paste(outcome.col.name,intervention.col.name, sep = ' ~ '))
  form = as.formula(paste(outcome.col.name,'~', paste(c(intervention.col.name, other.predictors), collapse = '+')))

  # for (perm.ind in 0:max.r) {
  perform.permutation.step = function(perm.ind) {

    t2 = Sys.time()
    #Permutation 0 is the actual data.
    if (perm.ind>0) {
      # #Rename the relevant permutation's column to pick it out.
      # old.col.name = names(perm.dt)[perm.ind+1]
      # data.table::setnames(x = perm.dt,
      #                      old = perm.ind+1,
      #                      new = "cluster.perm")

      #Shuffle the clusters between sites.
      perm.data.dt = data.table::rbindlist(
        data.table:::merge.data.table(
          x = perm.dt[permutation == perm.ind, .(site, cluster)],
          y = hypothetical.data.dt,
          # by.x = c("site", "cluster.perm"),
          # by.y = c("site", "cluster")
          by = c("site", "cluster")
        )$data.dt
        #Make sure to remove transition!
      )[get(intervention.col.name) != "transition"]
    } else {
      perm.data.dt = data.dt[get(intervention.col.name) != "transition"]
    }

    # print(names(perm.data.dt))
    # message(c('t1_d = ', Sys.time() - t2))

    #Put the statistic in the table we setup.
    if (statistic == 'ANOVA') {
      stat = anova(test.wilcoxon.ANOVA.form(data.dt = perm.data.dt, form = form))$`F value`[1]
      # data.table::set(x = stat.dt,
      #                 i = which(stat.dt[,perm.num == perm.ind]),
      #                 j = "stat",
      #                 value = anova(test.wilcoxon.ANOVA.form(data.dt = perm.data.dt, form = form))$`F value`[1])

    } else if (statistic == 'WMWU') { #WMWMU
      if (!stat.per.site) {
        # message(c('t2_d = ', Sys.time() - t2))
        # data.table::set(x = stat.dt,
        #                 i = which(stat.dt[,perm.num == perm.ind]),
        #                 j = "stat",
        #                 value = coin::statistic(coin::wilcox_test(form, data = perm.data.dt)))
        stat = coin::statistic(coin::wilcox_test(form, data = perm.data.dt))
        # message(c('t3_d = ', Sys.time() - t2))
      } else {
        # data.table::set(x = stat.dt,
        #                 i = which(stat.dt[,perm.num == perm.ind]),
        #                 j = "stat",
        #                 value = perm.data.dt[,.(stat = coin::statistic(coin::wilcox_test(form, .SD, exact=F))), by = site][,stat])
        stat = perm.data.dt[,.(stat = coin::statistic(coin::wilcox_test(form, .SD, exact=F))), by = site][,stat]
      }
    } else if (statistic == 'mean_diff') { #Mean difference
      diff_fn = function(x) x[2]-x[1]
      if (!stat.per.site) {
        # print(perm.data.dt[, mean(get(outcome.col.name)), by = c(intervention.col.name)][order(get(intervention.col.name)), diff(V1)])
        stat = perm.data.dt[, mean(get(outcome.col.name)), by = c(intervention.col.name)][order(get(intervention.col.name)), diff_fn(V1)]
      } else {
        stat = perm.data.dt[, mean(get(outcome.col.name)), by = c('site', intervention.col.name)][order(site, get(intervention.col.name)), diff_fn(V1), by = site][, V1]
      }
    } else if (statistic == 'risk_ratio') { # Risk ratio
      ratio_fn = function(x) x[2]/x[1]
      if (!stat.per.site) {
        stat = perm.data.dt[, mean(get(outcome.col.name)), by = c(intervention.col.name)][order(get(intervention.col.name)), ratio_fn(V1)]
      } else {
        stat = perm.data.dt[, mean(get(outcome.col.name)), by = c('site', intervention.col.name)][order(site, get(intervention.col.name)), ratio_fn(V1), by = site][, V1]
      }
    } else if (statistic == 'chisq') { #Mean difference
      if (!stat.per.site) {
        stat = perm.data.dt[, coin::statistic(coin::chisq_test(table(.(group = droplevels(get(intervention.col.name)), outcome = get(outcome.col.name)))))]
      } else {
        # stat = perm.data.dt[, mean(get(outcome.col.name)), by = c('site', intervention.col.name)][order(site, get(intervention.col.name)), diff(V1), by = site][, V1]
        stop('Per site not supported for chisq')
      }
    } else if (statistic == 'WMWU.DT') { #WMWMU
      # if (!stat.per.site) {
      # message(c('t2_d = ', Sys.time() - t2))

      # data.table::set(x = stat.dt,
      #                   i = which(stat.dt[,perm.num == perm.ind]),
      #                   j = "stat",
      #                   value =  test.wilcox.dt(perm.data.dt)$z)
      stat = test.wilcox.dt(perm.data.dt)$z
      # message(c('t3_d = ', Sys.time() - t2))
      # }
    } else {
      stop(paste(statistic, 'is not a supported statistic'))
    }


    # #Permutation 0 is the actual data.
    # if (perm.ind>0) {
    #   #Reset name to what it was before
    #   data.table::setnames(x = perm.dt,
    #                        old = perm.ind+1,
    #                        new = old.col.name)
    # }

    # message(c('t4_d = ', Sys.time() - t2))

    #Update progress (max 100 times)

    if (progress.bar == T) {
      if (max.r<=100) {
        setTxtProgressBar(pb, perm.ind/max.r)
      } else {
        if (perm.ind/max.r >= next.progress) {
          setTxtProgressBar(pb, perm.ind/max.r)
          next.progress = next.progress + 0.01
        }
      }
    }

    return(stat)
  }

  # result = lapply(0L:max.r, perform.permutation.step)
  # print(result)
  data.table::set(x = stat.dt,
                  j = "stat",
                  value = unlist(mclapply(0L:max.r, perform.permutation.step)))

  # stat.dt = cbind(stat.dt, rbindlist(result))

  if (progress.bar == T) {
    close(pb)
  }
  elapsed = Sys.time()-t
  message(paste("Time elapsed: "),hms::as_hms(elapsed))
  message("")

  #Also give it a z-transform
  data.table::set(x = stat.dt,
                  j = "z",
                  value = scale(stat.dt$stat, center = T, scale = T))


  return(stat.dt)
}

#' Do a wilcox test on a data.table.
#'
#' @param data.dt data.table with two-level grouping factor 'group' and outcome
#'   'outcome''
#' @param two.sided Do a two sided test?
#' @param tie.correction Apply tie correction (slightly slower, but sometimes
#'   necessary). If NULL, tie correction will be applied if there are.
#' @param stratification_var_name Variable name to be subtracted as a
#'   stratification variable (included with the intention to use Hodges-Lehmann
#'   position indicator, i.e., pseudomedian)
#' @param group_col_name Name of treatment column
#' @param outcome_col_name Name of outcome column
#' @return A data.table containing statistics, including z score and theoretical
#'   p value (e.g. z.dt$z).
#'
#' @export
test.wilcox.dt = function(data.dt,
                          two.sided = T,
                          tie.correction = NULL,
                          stratification_var_name = NULL,
                          group_col_name = 'group',
                          outcome_col_name = 'outcome') {

  #What proportion of values should be unique to apply tie correction (if not
  #explicitly enabled/disabled)
  tie.correction.threshold = .9

  setorder(data.dt, outcome)
  # }
  if (is.null(tie.correction)) {
    tie.correction = length(data.dt[,unique(outcome)]) < nrow(data.dt)*tie.correction.threshold
  }



  #Do WMW
  if (is.null(stratification_var_name)) {
    data.dt[, rank := frank(get(outcome_col_name), ties.method = 'average')]
  } else {
    data.dt[, rank := frank(get(outcome_col_name) - get(stratification_var_name), ties.method = 'average')]
  }
  # #Assign ranks to outcomes
  # if (!hodgeslehmann) {
  # } else {
  #   data.dt[, rank := senstrat::hodgeslehmann(y = data.dt$outcome,
  #                                             z = data.dt$group,
  #                                             st = data.dt$site,
  #                                             align = 'hl')]
  # }

  #Make a data.table with rank sums and n per group.
  wmw.dt = data.dt[,.(R = sum(rank), n = .N), by = group_col_name]


  #Calculate U for each group
  data.table::set(x = wmw.dt,
                  j = 'u',
                  value = wmw.dt[,R - (n*(n+1))/2])


  #Get minimum U, n for each group, and also theoretical mean.
  z.dt = cbind(wmw.dt[u == min(u), .(n.a=as.numeric(n), u = u)],
               wmw.dt[u == max(u), .(n.b=as.numeric(n))],
               wmw.dt[,.(m.u = prod(n)/2)])

  #Calculate theoretical SD, correcting for errors if requested.
  if (tie.correction == F) {
    z.dt[,sd.u := wmw.dt[,sqrt(prod(n)*(sum(n)+1)/12)]]
  } else {
    z.dt[,sd.u := sqrt((n.a*n.b/((n.a+n.b)*(n.a+n.b-1))) * ((((n.a+n.b)^3-(n.a+n.b))/12)-sum(data.dt[,(.N^3-.N)/12, by = outcome_col_name])))]
  }


  #Calculate z score for U
  data.table::set(x = z.dt,
                  j = 'z',
                  value = z.dt[,(u - m.u)/sd.u])


  data.table::set(x = z.dt,
                  j = 'p',
                  value = z.dt[,pnorm(z) * (1+two.sided)])

  return(z.dt)
}


#' Generate a table that holds a number of ways in which to permute sites to
#' different clusters.
#'
#' @param study.dt A study info data.table, containing site, cluster, and timing
#'   info.
#' @param max.r Number of permutations.
#' @param max.iterations Duplicates are avoided with a while loop, it will time
#'   out after this many iterations.
#' @return A data.table containing all the permutations of site to cluster.
#'
#' @export
generate.perm.dt = function(study.dt, max.r = 1000, max.iterations = 10) {


  #Find out roughly how many computations are possible.
  max.poss.r = study.dt[, .N, by = randomisation.group][, matrixStats::product(factorial(N))]

  #Adjust max iterations if necessary.
  if (max.poss.r < max.r) {
    warning(paste(max.r, 'permutations requested, but only',
                  max.poss.r, 'possible. Setting max.r to', max.poss.r))

    max.r = max.poss.r
  }

  # Set up a data table.
  perm.dt = data.table()
  iteration = 0

  while (iteration < max.iterations) {

    # Create a number of permutations.
    iteration.perm.dt = rbindlist(lapply(
      X = 1:max.r,
      FUN = function(x)
        study.dt[, .(permutation = max.r * iteration + x,
                     site = sample(site),
                     cluster), by = randomisation.group]
    ))

    # Add them to the other ones.
    perm.dt = rbindlist(list(perm.dt,
                             iteration.perm.dt),
                        use.names = TRUE)[order(permutation, cluster, randomisation.group, site)]

    # Check for uniqueness, hope you've got no semi-colons in your column names!
    perm.dt = perm.dt[permutation %in% perm.dt[, .(site_char = paste(site, collapse = ';')), by = permutation][!duplicated(site_char), permutation]]

    iteration = iteration + 1

    # If we've reached the right number, break and get the requested number.
    if (perm.dt[, uniqueN(permutation)] > max.r) {
      perm.dt = perm.dt[permutation %in% perm.dt[, unique(permutation)][1:max.r]]
      break
    }

    # Warning for reaching the limit, should probably make up something better for
    # situations where there are not many possible permutations.
    if (iteration == max.iterations & all.equal(perm.dt[, uniqueN(permutation)], max.r) != TRUE) {
      warning(paste('Generating permutations stopped with only',
                    perm.dt[, uniqueN(permutation)],
                    'unique permutations.'))
    }
  }

  # Number iterations 1:max
  perm.dt[, permutation := as.numeric(as.factor(permutation))]

  return(perm.dt)
}

#' Applies a few tests to a statistic table, generated by generate.stat.dt I
#' don't think this is as good as an overall wilcoxon
#'
#' @param stat.dt A data.table of the statistic with minimally columns for stat,
#'   permuted, and I guess site if you want that in the plot
#' @return A list with a few tests.
#'
#' @export
test.stat.table.per.site = function(stat.dt) {

  plot = ggplot2::ggplot(data=stat.dt,ggplot2::aes(x=stat, y = ..density..))


  if ('site' %in% colnames(stat.dt)) {
    plot = plot +
      ggplot2::geom_density(ggplot2::aes(fill=factor(site)), adjust=1.5, alpha = 0.5, position = "stack")

  }

  tests = list(
    tt = t.test(stat ~ permuted, stat.dt),
    it = coin::independence_test(stat ~ permuted, stat.dt, distribution = "asymptotic"),
    wt = coin::wilcox_test(stat ~ permuted, stat.dt),
    ot = coin::oneway_test(stat ~ permuted, stat.dt))

  return(list(tests = tests,
              plot = plot))
}

#' Applies a few tests to a statistic table, generated by generate.stat.dt
#'
#' @param stat.dt A data.table of the statistic with minimally columns for stat,
#'   permuted. First entry is the observed value, then R permuted values.
#' @return A list with a two-tailed p-value.
#'
#' @export
test.stat.table = function(stat.dt) {

  result = list(
    p = sum(stat.dt[2:.N, abs(stat)] > stat.dt[1,abs(stat)]) / (nrow(stat.dt)-1)
  )

}


#' Applies a two-way ANOVA to Wilcoxon ranks
#'
#' @param data.dt A data.table with results from each participant, an outcome, a
#'   group (i.e. effect of interest), and a time
#' @return Results of the two-way ANOVA.
#'
#' @export
test.wilcoxon.ANOVA = function(data.dt, outcome.col.name = 'outcome', intervention.col.name = 'group', other.predictors = 'time') {

  form = as.formula(paste(outcome.col.name,'~',intervention.col.name, ' + ', paste(other.predictors, collapse = '+')))
  return(test.wilcoxon.ANOVA.form(data = data.dt, form = form))

}

#' Applies a two-way ANOVA to Wilcoxon ranks
#'
#' @param data.dt A data.table with results from each participant, an outcome, a
#'   group (i.e. effect of interest), and a time
#' @return Results of the two-way ANOVA.
#'
#' @export
test.wilcoxon.ANOVA.form = function(data.dt, form) {

  return(aov(form, data = data.dt))

}

#' Cut down version of wilcox.test that only returns the pseudo-median without
#' CIs. Uses Rfast for a little bit of a speed boost.
#'
#' @param x Vector of values.
#' @param max_length Because the outer product is calculated, large numbers of
#'   observations will result in a vector that cannot be allocated.
#' @return Pseudo-median of x
#'
#' @export
pseudo_median = function(x, max_length = 20000) {

  if (length(x) > max_length) {
    message(paste0('pseudo_median: x has more than ', length(x), ' elements, sampling ', max_length))
    x = sample(x = x, size = max_length)
  }

  ## These are sample based limits for the median
  ## [They don't work if alpha is too high]
  mumin <- min(x)
  mumax <- max(x)

  ## wdiff(d, zq) returns the absolute difference between
  ## the asymptotic Wilcoxon statistic of x - mu - d and
  ## the quantile zq.
  wdiff <- function(d, zq) {
    xd <- x - d
    xd <- xd[xd != 0]
    nx <- length(xd)
    dr <- rank(abs(xd))
    zd <- sum(dr[xd > 0]) - nx * (nx + 1)/4

  }

  diffs = Rfast::Sort(Rfast::upper_tri(Rfast::Outer(x, x, "+"), diag = TRUE) / 2)

  ESTIMATE <- c("(pseudo)median" =
                  uniroot(wdiff, c(mumin, mumax), tol=1e-4,
                          zq = 0)$root)

  return(ESTIMATE)

}
